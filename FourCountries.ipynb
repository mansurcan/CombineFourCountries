{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "microsoft": {
          "language": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "base_path = 'abfss://fssynwallodp01prod@sasynwallodp01prod.dfs.core.windows.net/'\n",
        "\n",
        "subscriptions_prices_se_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_prices_country_se/'\n",
        "subscriptions_prices_dk_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_prices_country_dk/'\n",
        "subscriptions_prices_fi_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_prices_country_fi/'\n",
        "subscriptions_prices_no_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_prices_country_no/'\n",
        "\n",
        "subscriptions_details_se_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_details_country_se/'\n",
        "subscriptions_details_dk_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_details_country_dk/'\n",
        "subscriptions_details_fi_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_details_country_fi/'\n",
        "subscriptions_details_no_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_details_country_no/'\n",
        "\n",
        "subscriptions_se_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_country_se/'\n",
        "subscriptions_dk_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_country_dk/'\n",
        "subscriptions_fi_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_country_fi/'\n",
        "subscriptions_no_silver_path = base_path + 'Silver/Datastore/appxite_subscriptions_country_no/'\n",
        "\n",
        "customer_details_se_silver_path = base_path + 'Silver/Datastore/appxite_customer_details_country_se'\n",
        "customer_details_dk_silver_path = base_path + 'Silver/Datastore/appxite_customer_details_country_dk'\n",
        "customer_details_fi_silver_path = base_path + 'Silver/Datastore/appxite_customer_details_country_fi'\n",
        "customer_details_no_silver_path = base_path + 'Silver/Datastore/appxite_customer_details_country_no'\n",
        "\n",
        "cdm_account_gold = base_path + 'Gold/CDM/Account'\n",
        "\n",
        "subscriptions_prices_columns = [\"subscriptionId\", \"TotalCost\"]\n",
        "\n",
        "subscriptions_prices_se = (spark.read.load(subscriptions_prices_se_silver_path, format='delta').select(subscriptions_prices_columns).withColumn(\"dss_country\", lit(\"se\")))\n",
        "subscriptions_prices_dk = (spark.read.load(subscriptions_prices_dk_silver_path, format='delta').select(subscriptions_prices_columns).withColumn(\"dss_country\", lit(\"dk\")))\n",
        "subscriptions_prices_fi = (spark.read.load(subscriptions_prices_fi_silver_path, format='delta').select(subscriptions_prices_columns).withColumn(\"dss_country\", lit(\"fi\")))\n",
        "subscriptions_prices_no = (spark.read.load(subscriptions_prices_no_silver_path, format='delta').select(subscriptions_prices_columns).withColumn(\"dss_country\", lit(\"no\")))\n",
        "\n",
        "subscriptions_details_columns = [\"Id\", \"AutoRenewalDetails\", \"StartDate\"]\n",
        "\n",
        "subscriptions_details_se = (spark.read.load(subscriptions_details_se_silver_path, format='delta').select(subscriptions_details_columns).withColumn(\"dss_country\", lit(\"se\")))\n",
        "subscriptions_details_dk = (spark.read.load(subscriptions_details_dk_silver_path, format='delta').select(subscriptions_details_columns).withColumn(\"dss_country\", lit(\"dk\")))\n",
        "subscriptions_details_fi = (spark.read.load(subscriptions_details_fi_silver_path, format='delta').select(subscriptions_details_columns).withColumn(\"dss_country\", lit(\"fi\")))\n",
        "subscriptions_details_no = (spark.read.load(subscriptions_details_no_silver_path, format='delta').select(subscriptions_details_columns).withColumn(\"dss_country\", lit(\"no\")))\n",
        "\n",
        "subscriptions_columns = [\"Id\", \"Status\", \"Name\", \"Vendor\", \"Quantity\", \"ExpirationTimestamp\",\"x_on_behalf_of\"]\n",
        "\n",
        "subscriptions_se = (spark.read.load(subscriptions_se_silver_path, format='delta').select(subscriptions_columns).withColumn(\"dss_country\", lit(\"se\")))\n",
        "subscriptions_dk = (spark.read.load(subscriptions_dk_silver_path, format='delta').select(subscriptions_columns).withColumn(\"dss_country\", lit(\"dk\")))\n",
        "subscriptions_fi = (spark.read.load(subscriptions_fi_silver_path, format='delta').select(subscriptions_columns).withColumn(\"dss_country\", lit(\"fi\")))\n",
        "subscriptions_no = (spark.read.load(subscriptions_no_silver_path, format='delta').select(subscriptions_columns).withColumn(\"dss_country\", lit(\"no\")))\n",
        "\n",
        "customer_details_columns = [\"Id\", \"ErpId\", \"VatNumber\", \"RegistrationNumber\", \"PartnerName\"]\n",
        "\n",
        "customer_details_se = (spark.read.load(customer_details_se_silver_path, format='delta').select(customer_details_columns).withColumn(\"dss_country\", lit(\"se\")))\n",
        "customer_details_dk = (spark.read.load(customer_details_dk_silver_path, format='delta').select(customer_details_columns).withColumn(\"dss_country\", lit(\"dk\")))\n",
        "customer_details_fi = (spark.read.load(customer_details_fi_silver_path, format='delta').select(customer_details_columns).withColumn(\"dss_country\", lit(\"fi\")))\n",
        "customer_details_no = (spark.read.load(customer_details_no_silver_path, format='delta').select(customer_details_columns).withColumn(\"dss_country\", lit(\"no\")))\n",
        "\n",
        "cdm_account_columns = [\"accountId\",\"ErpId\",\"VatNumber\",\"RegistrationNumber\",\"PartnerName\"]\n",
        "\n",
        "# take only accountNumber from Account table is in the cdm : accountNumber = iifNull(toString(ErpId),VatNumber, toString(RegistrationNumber))\n",
        "cdm_account = spark.read.load(cdm_account_gold, format='delta').select(cdm_account_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "display(cdm_account.limit(5))\n",
        "cdm_account.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Combine all four DataFrames into a single DataFrame\n",
        "combined_subscriptions_prices = (subscriptions_prices_se\n",
        "                                 .union(subscriptions_prices_dk)\n",
        "                                 .union(subscriptions_prices_fi)\n",
        "                                 .union(subscriptions_prices_no))\n",
        "\n",
        "# Rename the \"subscriptionId\" column to \"Id\" in combined_subscriptions_prices DataFrame\n",
        "combined_subscriptions_prices = combined_subscriptions_prices.withColumnRenamed(\"subscriptionId\", \"Id\")\n",
        "\n",
        "# Count the total number of rows in the combined DataFrame\n",
        "total_rows = combined_subscriptions_prices.count()\n",
        "print(f\"Total number of rows combined_subscriptions_prices: {total_rows}\")\n",
        "\n",
        "# Count the number of distinct rows based on all columns\n",
        "distinct_rows = combined_subscriptions_prices.distinct().count()\n",
        "print(f\"Total number of distinct rows combined_subscriptions_prices: {distinct_rows}\")\n",
        "\n",
        "display(combined_subscriptions_prices.limit(5))\n",
        "combined_subscriptions_prices.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "# Combine all four DataFrames into a single DataFrame\n",
        "subscriptions_details_combined = (subscriptions_details_se\n",
        "                                 .union(subscriptions_details_dk)\n",
        "                                 .union(subscriptions_details_fi)\n",
        "                                 .union(subscriptions_details_no))\n",
        "\n",
        "# Count the total number of rows in the combined DataFrame\n",
        "total_rows = subscriptions_details_combined.count()\n",
        "print(f\"Total Rows: {total_rows}\")\n",
        "\n",
        "# Count the number of distinct rows based on all columns\n",
        "distinct_rows = subscriptions_details_combined.distinct().count()\n",
        "print(f\"Distinct Rows: {distinct_rows}\")\n",
        "\n",
        "display(subscriptions_details_combined.limit(5))\n",
        "subscriptions_details_combined.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "delta_table_path = 'abfss://fssynwallodp01prod@sasynwallodp01prod.dfs.core.windows.net/Gold/test/SubscriptionDetailsCombined/'\n",
        "\n",
        "subscriptions_details_combined.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").format('delta').save(delta_table_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "# Combine all four DataFrames into a single DataFrame\n",
        "combined_subscriptions = (subscriptions_se\n",
        "                         .union(subscriptions_dk)\n",
        "                         .union(subscriptions_fi)\n",
        "                         .union(subscriptions_no))\n",
        "\n",
        "# Count the total number of rows in the combined DataFrame\n",
        "total_rows = combined_subscriptions.count()\n",
        "print(f\"Total Rows: {total_rows}\")\n",
        "\n",
        "# Count the number of distinct rows based on all columns\n",
        "distinct_rows = combined_subscriptions.distinct().count()\n",
        "print(f\"Distinct Rows: {distinct_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "# Combine all four DataFrames into a single DataFrame\n",
        "combined_customer_details = (customer_details_se\n",
        "                           .union(customer_details_dk)\n",
        "                           .union(customer_details_fi)\n",
        "                           .union(customer_details_no))\n",
        "\n",
        "# Count the total number of rows in the combined DataFrame\n",
        "total_rows = combined_customer_details.count()\n",
        "print(f\"Total Rows: {total_rows}\")\n",
        "\n",
        "# Count the number of distinct rows based on all columns\n",
        "distinct_rows = combined_customer_details.distinct().count()\n",
        "print(f\"Distinct Rows: {distinct_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "combined_subscriptions.printSchema()\n",
        "subscriptions_details_combined.printSchema()\n",
        "combined_subscriptions_prices.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Perform inner joins\n",
        "joined_df = subscriptions_details_combined \\\n",
        "    .join(combined_subscriptions, subscriptions_details_combined[\"Id\"] == combined_subscriptions[\"Id\"], \"full\") \\\n",
        "    .join(combined_subscriptions_prices, combined_subscriptions[\"Id\"] == combined_subscriptions_prices[\"Id\"], \"full\") \\\n",
        "    .select(\n",
        "        subscriptions_details_combined[\"Id\"].alias(\"subscriptionId\"),\n",
        "        subscriptions_details_combined[\"AutoRenewalDetails\"],\n",
        "        subscriptions_details_combined[\"StartDate\"],\n",
        "        combined_subscriptions[\"Status\"],\n",
        "        combined_subscriptions[\"Name\"],\n",
        "        combined_subscriptions[\"Vendor\"],\n",
        "        combined_subscriptions[\"Quantity\"],\n",
        "        combined_subscriptions[\"ExpirationTimestamp\"],\n",
        "        combined_subscriptions[\"x_on_behalf_of\"],\n",
        "        combined_subscriptions_prices[\"TotalCost\"]\n",
        "    )\n",
        "\n",
        "# Show the joined DataFrame\n",
        "display(joined_df.limit(5))\n",
        "joined_df.printSchema()\n",
        "print(f\"Joined DataFrame has {joined_df.count()} rows.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Filter rows where \"Id\" is not empty or null\n",
        "filtered_df = joined_df.filter(col(\"subscriptionId\").isNotNull() & (col(\"subscriptionId\") != \"\"))\n",
        "\n",
        "# Show the filtered DataFrame\n",
        "display(filtered_df.limit(5))\n",
        "filtered_df.printSchema()\n",
        "print(f\"Filtered DataFrame has {filtered_df.count()} rows.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "from pyspark.sql.functions import col, lit, when\n",
        "\n",
        "# Use when and otherwise to create the accountNumber column\n",
        "cdm_account_accountNumber = cdm_account.withColumn(\n",
        "    \"accountNumber\",\n",
        "    when(col(\"ErpId\").isNotNull(), col(\"ErpId\").cast(\"string\"))\n",
        "    .otherwise(when(col(\"VatNumber\").isNotNull(), col(\"VatNumber\").cast(\"string\"))\n",
        "    .otherwise(col(\"RegistrationNumber\").cast(\"string\")))\n",
        ")\n",
        "\n",
        "# Show the result DataFrame\n",
        "cdm_account_accountNumber.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "from pyspark.sql.functions import col, lit, when\n",
        "\n",
        "# Use when and otherwise to create the accountNumber column\n",
        "combined_customer_details_accountNumber = combined_customer_details.withColumn(\n",
        "    \"accountNumber\",\n",
        "    when(col(\"ErpId\").isNotNull(), col(\"ErpId\").cast(\"string\"))\n",
        "    .otherwise(when(col(\"VatNumber\").isNotNull(), col(\"VatNumber\").cast(\"string\"))\n",
        "    .otherwise(col(\"RegistrationNumber\").cast(\"string\")))\n",
        ")\n",
        "\n",
        "# Show the result DataFrame\n",
        "combined_customer_details_accountNumber.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "combined_customer_details_accountNumber.printSchema()\n",
        "cdm_account_accountNumber.printSchema()\n",
        "filtered_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Perform an inner join on the \"PK x_on_behalf_of\" column in filtered_df and \"PK Id\" column in combined_customer_details_accountNumber\n",
        "subscription_customer_details_joined = filtered_df.join(\n",
        "    combined_customer_details_accountNumber,\n",
        "    filtered_df[\"x_on_behalf_of\"] == combined_customer_details_accountNumber[\"Id\"],\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "# Show the joined DataFrame\n",
        "display(subscription_customer_details_joined.limit(5))\n",
        "subscription_customer_details_joined.printSchema()\n",
        "print(f\"Joined DataFrame has {subscription_customer_details_joined.count()} rows.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "# Perform an inner join based on \"accountNumber\" and \"PartnerName\"\n",
        "final_df = subscription_customer_details_joined.join(\n",
        "    cdm_account_accountNumber,\n",
        "    on=[\"accountNumber\", \"PartnerName\"],\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "# Show the joined DataFrame\n",
        "display(final_df.limit(5))\n",
        "final_df.printSchema()\n",
        "print(f\"Joined DataFrame has {final_df.count()} rows.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "from pyspark.sql.functions import col, when, to_date, expr\n",
        "from pyspark.sql.types import DecimalType\n",
        "\n",
        "# Select and transform columns\n",
        "transformed_df = final_df.select(\n",
        "    col(\"subscriptionId\"),\n",
        "    col(\"AutoRenewalDetails\"),\n",
        "    to_date(col(\"StartDate\")).alias(\"StartDate\"),  # Transform StartDate to date\n",
        "    when(col(\"Status\") == \"Enabled\", 1).otherwise(0).alias(\"Active\"),  # Transform Status to Active column\n",
        "    col(\"Name\"),\n",
        "    col(\"Vendor\").alias(\"VendorName\"),  # Rename Vendor to VendorName\n",
        "    col(\"Quantity\").cast(DecimalType(10, 2)).alias(\"Quantity\"),  # Transform Quantity to decimal\n",
        "    to_date(col(\"ExpirationTimestamp\")).alias(\"LatestEndDate\"),  # Transform ExpirationTimestamp to date\n",
        "    col(\"TotalCost\").cast(DecimalType(10, 2)).alias(\"TotalPrice\"),  # Transform TotalCost to decimal\n",
        "    col(\"accountId\")\n",
        ")\n",
        "\n",
        "# Show the transformed DataFrame\n",
        "display(transformed_df.limit(5))\n",
        "transformed_df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "base_path = 'abfss://fssynwallodp01prod@sasynwallodp01prod.dfs.core.windows.net/'\n",
        "subscription_path = base_path + 'Gold/CDM/Subscription/'\n",
        "\n",
        "subscription = spark.read.load(subscription_path, format='delta')\n",
        "\n",
        "display(subscription.limit(5))\n",
        "subscription.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "subscription_renamed = subscription.withColumnRenamed(\"Active\", \"Status\")\n",
        "subscription_renamed.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StringType, TimestampType\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the values you want to add\n",
        "current_date = datetime.now()\n",
        "\n",
        "dss_load_time = current_date\n",
        "dss_create_time = current_date\n",
        "dss_update_time = current_date\n",
        "dss_country = \"country\"\n",
        "dss_record_source = \"df_cdm_subscription_attributes\"\n",
        "\n",
        "# Add the columns and values to the DataFrame\n",
        "subscription_df = subscription \\\n",
        "    .withColumn(\"dss_load_time\", F.lit(dss_load_time).cast(TimestampType())) \\\n",
        "    .withColumn(\"dss_create_time\", F.lit(dss_create_time).cast(TimestampType())) \\\n",
        "    .withColumn(\"dss_update_time\", F.lit(dss_update_time).cast(TimestampType())) \\\n",
        "    .withColumn(\"dss_record_source\", F.lit(dss_record_source).cast(StringType())) \\\n",
        "    .withColumn(\"dss_country\", F.lit(dss_country).cast(StringType()))\n",
        "\n",
        "subscription_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "display(subscription_df.limit(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "delta_table_path = 'abfss://fssynwallodp01prod@sasynwallodp01prod.dfs.core.windows.net/Gold/CDM/Subscription/'\n",
        "\n",
        "subscription_renamed.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").format('delta').save(delta_table_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "from pyspark.sql.functions import countDistinct, col\n",
        "from datetime import datetime\n",
        "\n",
        "# Current date\n",
        "current_date = datetime.now().strftime('%d-%m-%Y')\n",
        "\n",
        "subscription_gold_path= 'Gold/CDM/Subscription/'\n",
        "\n",
        "# Print current date and silver_se_path\n",
        "print(f\"Current Date: {current_date}\")\n",
        "print(f\"Order In Sales Path: {subscription_gold_path}\\n\")\n",
        "\n",
        "# Count the total number of rows\n",
        "total_rows = subscription.count()\n",
        "\n",
        "# Count the number of distinct 'Id' rows\n",
        "distinct_id_rows = subscription.select(countDistinct('subscriptionId')).first()[0]\n",
        "\n",
        "# Filter rows where 'Id' is empty\n",
        "empty_id_rows_df = subscription.filter(col('subscriptionId').isNull())\n",
        "\n",
        "# Count rows where 'Id' is empty\n",
        "id_rows = empty_id_rows_df.count()\n",
        "\n",
        "# Display the comparison\n",
        "print(f\"Total Rows: {total_rows}\")\n",
        "print(f\"Distinct 'Id' Rows: {distinct_id_rows}\")\n",
        "print(f\"Id Rows empty: {id_rows}\\n\")\n",
        "\n",
        "# Display rows with empty 'Id'\n",
        "# display(empty_id_rows_df)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
